# pentest-toolbox

## Description

A suite of the following pentesting related scripts:

- ___ai___: Send a query from the terminal to the OpenAI API (or locally to Ollama) and get the reply back as output in the terminal.

- ___bruteforce___: Simple password bruteforcing script utilizing the __requests__ python library.

- ___bfselenium___: Another password bruteforcer through browser control with __selenium__. 

- ___webscrape___: A set of scripts for site-crawling, webscraping and filtering for specific content.

The toolbox mostly consists of scripts from [edu-pentest-toolbox](https://github.com/miwashi-edu/edu-pentest-toolbox.git) by [miwashi](https://github.com/miwashi), and was a part of the course _Programming for pentesters_ at ITHS 2024.

The ___ai___ feature is my contribution to the toolbox, and is what the rest of this README will focus on specificly. Perhaps in the future more documentation about the other scripts will come - meanwhile the code is not terribly long and complicated, and some of the scripts also has built in help flags (`--help`) that may be of guidance.

### ai script

It's very much in it's infancy but currently it has the following features:

- Query various LLM:s directly from the terminal via the OpenAI API, as well as locally hosted models via the Ollama API to ensure privacy and access to a wider library of open source models.

- Each API call takes two messages from the user:
    1. A user message (required): your question to the LLM, the article it should summarize, etc. This is piped to the script.
    2. A system message (optional): a more general instruction for the desired behaviour of the LLM. 

- Pipe the output from one LLM call with a certain system message and instruction, to another LLM call (or even another LLM model) for further processing.

- Use predifined and detailed system messages that can quickly be used for a certain use case. Some (very) simple examples can be found under system_prompts.

- Redirect the output (LLM reply) directly in the terminal or save to a file, or both.

## Setup

Follow the instructions at [OpenAI API quickstart](https://platform.openai.com/docs/quickstart?context=python) to get set up with an account and generate an API key.

Follow the instructions there for making sure the API key can be used by the OpenAI Python library, eithery globally or on a per-project-basis. The short version is to export your API key: `export OPENAI_API_KEY='your-api-key-here'`

You may also follow the quickstart to easily make your own first API call without the program in this repository, otherwise now clone this repo:

`git clone https://github.com/sparkhound772/pentest-toolbox.git`

`cd pentest-toolbox`

Now either just run the scripts directly or and pip install. For the latter:

Optionally initialize a virtual environment:
  
`python -m venv pen_tools_env`

Install:

`pip install .`

## Usage

If installed the scripts are available under their respective names. Perhaps the easiest way to quickly know them is to check their names in __pyproject.toml__

Let's run the ___ai___ script.

![ai usage](docs/images/ai_example.png)

The default behaviour, if only the required user message is piped to the program, is to call gpt-3.5-turbo from OpenAI.

If the `--sysm` flag is omitted system message by default will simply be: "You are a helpful assistant".

To change the specific model being called, alter the `model_name` variable in the script and again pip install.  

See [OpenAI API models](https://platform.openai.com/docs/models/) and [Ollama library](https://ollama.com/library)

## Future improvements

- Make it possible to choose model directly when running the program.

- Create more prepared system promts under system_prompts, and make them more detailed for specific use cases.

## Acknowledgements

The ai script is very much inspired by:

![danielmiessler/fabric](https://github.com/danielmiessler/fabric.git)

The script in this repo is very rudimentary in comparison, so please check out that repository for more advanced and mature tool for the same purpose.

Thanks also to ChatGPT for the help with the script.
