# pentest-toolbox

## Description

A suite of the following pentesting related scripts:

- ___ai___: Send a query from the terminal to the OpenAI API (or locally from Ollama) and get the reply back as output in the terminal.

- ___bruteforce___: Simple password bruteforcing script utilizing the __requests__ python library.

- ___bfselenium___: Another password bruteforcer through browser control with __selenium__. 

- ___webscrape___: A set of scripts for site-crawling, webscraping and filtering for specific content.


The toolbox mostly consists of scripts from [edu-pentest-toolbox](https://github.com/miwashi-edu/edu-pentest-toolbox.git) by [miwashi](https://github.com/miwashi), and was a part of the course _Programming for pentesters_ at ITHS 2024.

### ai script

The ___ai___ feature is my contribution to the toolbox and hypothetically allows for more flexible and private utilization of AI than using the browser chat interface of OpenAI. 

It's very much in it's infancy but currently or very soon it has the following features:

- Separately from the user query to the LLM as with the browser interfaces, a separate system message may be provided which customizes the behaviour of the LLM for the query, allowing for specific use cases (ex. "Summarize this information according to the following criteria... etc.").

- Pipe the output of one LLM query with a certain use case, to another query to the LLM with another use case (and so on), and output the reply in the terminal or save directly to a file, or both.

- Use the script to query a locally running LLM with Ollama, so that no confidential data has to leave the system to ensure privacy. This however has quite high hardware requirements if the more powerful LLM:s are to work satisfactorily.

## Setup

`git clone https://github.com/sparkhound772/pentest-toolbox.git`

`cd pentest-toolbox`

Optionally initialize virtual environment and pip install:

`python -m venv pen_tools_env`

`pip install .`

Or just run the scripts directly without installing.

## Usage

If installed the scripts are available under their respective names. Perhaps the easiest way to quickly know them is to check their names in __pyproject.toml__

Let's run the ___ai___ script. This requires a string to be piped to the script:

![ai usage](docs/images/ai_example.png)

## Future improvements

- Create more prepared system promts under system_prompts, and make them more detailed for specific use cases.
